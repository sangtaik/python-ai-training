{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00f508b8",
   "metadata": {},
   "source": [
    "## Googlenet 영상인식 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436dd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opencv Deep learning Tutorial\n",
    "# https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n",
    "\n",
    "# Caffe Model Zoo : github.com/BVLC/caffe\n",
    "## 모델 파일 : dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel\n",
    "## 설정 파일 : github.com/BVLC/caffe/blob/master/models/bvlc_googlenet/deploy.prototxt\n",
    "\n",
    "\n",
    "# ONNX Model Zoo : github.com/onnx/models\n",
    "# 모델파일: https://github.com/onnx/models/tree/master/vision/classification/inception_and_googlenet/googlenet\n",
    "\n",
    "# 클래스 이름 파일 : github.com/opencv/opencv/blob/4.1.0/samples/data/dnn/\n",
    "\n",
    "# readNet(model, config)\n",
    "# model, config\n",
    "\n",
    "# 실행순서\n",
    "# cv2.dnn.readNet(model, config)-> ret, 객체생성\n",
    "# blobFromImage(image, scalefactor, size, mean, swapRB, crop) -> retval\n",
    "# scalefactor: Multiply by factor\n",
    "# image has BGR ordering and swapRB is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2983eed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "0.59207493\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "########### googLeNet 영상인식\n",
    "# 입력크기: 224 x 224\n",
    "# 컬러: BGR\n",
    "# 밝기평균값: (104, 117, 123)\n",
    "\n",
    "\n",
    "########## 입력 영상 불러오기\n",
    "\n",
    "# filename = 'googlenet/apple2.png'\n",
    "filename = './googlenet/fig/scooter.jpg'\n",
    "\n",
    "# if len(sys.argv) > 1: \n",
    "#     filename = sys.argv[1]\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "######### 네트워크 불러오기\n",
    "\n",
    "# Caffe\n",
    "model = 'googlenet/bvlc_googlenet.caffemodel'\n",
    "config = 'googlenet/deploy.prototxt'\n",
    "\n",
    "# ONNX\n",
    "# model = 'googlenet/googlenet-9.onnx'\n",
    "# config = ''\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Network load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "########## 클래스 이름 불러오기\n",
    "\n",
    "classNames = []\n",
    "with open('googlenet/classification_classes_ILSVRC2012.txt', 'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "########### 추론\n",
    "# blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n",
    "# retval: numpy.ndarry.shape = (N,C,H,W), dtype = numpy.float32\n",
    "## N = number of image, C = channels, H = height, W = width\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123), \n",
    "                             swapRB = False)\n",
    "net.setInput(blob)\n",
    "prob = net.forward()\n",
    "print(prob.shape)\n",
    "\n",
    "########### 추론 결과 확인 & 화면 출력\n",
    "\n",
    "out = prob.flatten() # 1d array\n",
    "classId = np.argmax(out)\n",
    "confidence = out[classId]\n",
    "print(confidence)\n",
    "text = f'{classNames[classId]} ({confidence * 100:4.2f}%)'\n",
    "cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e13fb3",
   "metadata": {},
   "source": [
    "## OpenCV DNN 얼굴검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/opencv/opencv/tree/master/samples/dnn/face_detector\n",
    "# deploy.prototxt.txt, download-weights.py.txt, opencv_face_detector.pbtxt.text 다운로드\n",
    "\n",
    "# Caffe    https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
    "\n",
    "# Tensorflow  https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180220_uint8/opencv_face_detector_uint8.pb\n",
    "\n",
    "## 참고 사이트\n",
    "# https://deep-learning-study.tistory.com/299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56da7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('opencv_face_detector/fig/sunglass.png')\n",
    "\n",
    "if img is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "    \n",
    "model = './opencv_face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config = './opencv_face_detector/deploy.prototxt'\n",
    "\n",
    "face_net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if face_net.empty():\n",
    "    print('Net open failed')\n",
    "    sys.exit()\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                            swapRB=False)\n",
    "\n",
    "face_net.setInput(blob)\n",
    "out = face_net.forward()\n",
    "\n",
    "detect = out[0, 0, :, :]\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        # out matrix에서 x1, y1, x2, y2 값이 0 ~1로 normalize 되어 있음\n",
    "        \n",
    "        x1 = int(detect[i, 3]*w)\n",
    "        y1 = int(detect[i, 4]*h)\n",
    "        x2 = int(detect[i, 5]*w)\n",
    "        y2 = int(detect[i, 6]*h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2),\n",
    "                     (0, 0, 255))\n",
    "        \n",
    "        text = 'Face: {}%'.format(round(confidence, 2))\n",
    "        cv2.putText(img, text, (x1, y1-1), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686ff91",
   "metadata": {},
   "source": [
    "## OpenCV DNN webcam 얼굴검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa1eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "## Caffe` 학습모델\n",
    "model = 'opencv_face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel'\n",
    "config = 'opencv_face_detector/deploy.prototxt'\n",
    "\n",
    "## Tensorflow 학습모델\n",
    "# model = 'opencv_face_detector/opencv_face_detector_uint8.pb'\n",
    "# config = 'opencv_face_detector/opencv_face_detector.pbtxt'\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123))\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()# out.shape=(1,1, 200, 7)\n",
    "    \n",
    "        \n",
    "    detect = out[0, 0, :, :] ##0, 0, 사용안함\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "           \n",
    "            # out matrix에서 x1, y1, x2, y2 값이 0 ~1로 normalize 되어 있음\n",
    "            x1 = int(detect[i, 3] * w)\n",
    "            y1 = int(detect[i, 4] * h)\n",
    "            x2 = int(detect[i, 5] * w)\n",
    "            y2 = int(detect[i, 6] * h)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "\n",
    "            label = f'Face: {confidence:4.2f}'\n",
    "            cv2.putText(frame, label, (x1, y1 - 1), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a173962-e006-4ed3-a2ef-14eed1eab121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
