{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83710a36",
   "metadata": {},
   "source": [
    "# CNN_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a236713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencv version =  4.5.5\n",
      "tensorflow version =  2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print('opencv version = ', cv2.__version__)\n",
    "print('tensorflow version = ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75854ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "Y_test = keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb53b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolution 신경망\n",
    "model =  keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size = (3,3), input_shape = (28, 28, 1),\n",
    "                              activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = 2))\n",
    "# model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885119fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a310c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "  os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70427c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath=\"./model/{epoch:003d}-{val_loss:.4f}.h5\"\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test),\n",
    "                    epochs = 30, batch_size = 200, verbose = 1,\n",
    "                    callbacks = [early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85dd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model import\n",
    "print('\\n Test accuracy: {:.4f}%'.format(model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('./model_mnist/')\n",
    "model.save('./model_mnist/', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tf2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m tf2onnx.convert --saved-model model_mnist --output model_mnist.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcba1fd",
   "metadata": {},
   "source": [
    "# opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59ef0378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 2.0 10.0\n",
      "0.5 2.5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAACmCAYAAAB5qlzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAACjUlEQVR4nO3aMW7DUAwFwTDQ/a9Ml65iwIX2J/FMq0KvEBYsNLv7BUDj+/QAgE8iugAh0QUIiS5ASHQBQqILELpePZwZ/5Nxq92dE+/1bXO3n75tly5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgNB1egDwtLunJ/w5M3N6wltcugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILELpePdzdase/MDOnJwC/nEsXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQuk4PAJ5m5vQEbubSBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2A0Ozu6Q0AH8OlCxASXYCQ6AKERBcgJLoAIdEFCD0AVP4VUPF1GgEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# img = cv2.imread('./googlenet/fig/apple2.png', 0)\n",
    "img = np.zeros((4,4), np.uint8)\n",
    "img[2:, :2] = 1\n",
    "# _, img = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY_INV)\n",
    "m = cv2.moments(img)\n",
    "\n",
    "print(m['m00'], m['m10'], m['m01'] )\n",
    "cx = m['m10'] / m['m00']\n",
    "cy = m['m01'] / m['m00']\n",
    "print(cx, cy)\n",
    "h, w = img.shape[:2]\n",
    "# print(h, w)\n",
    "# # # affine 행렬 생성\n",
    "aff = np.array([[1, 0, w/2 - (cx + 0.5) ], [0, 1, h/2 - (cy + 0.5)]], dtype=np.float32)\n",
    "\n",
    "# # # warpAffine을 이용해 기하학 변환\n",
    "dst = cv2.warpAffine(img, aff, (0, 0))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img, 'gray'),plt.axis('off')\n",
    "plt.subplot(122),plt.imshow(dst, 'gray'),plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f42ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (51.76%)\n",
      "6 (94.08%)\n",
      "7 (99.98%)\n",
      "8 (99.96%)\n",
      "1 (99.81%)\n",
      "2 (99.98%)\n",
      "3 (100.00%)\n",
      "4 (100.00%)\n",
      "5 (100.00%)\n",
      "6 (99.88%)\n",
      "7 (100.00%)\n",
      "8 (100.00%)\n",
      "9 (100.00%)\n",
      "6 (97.36%)\n",
      "2 (95.82%)\n",
      "3 (99.82%)\n"
     ]
    }
   ],
   "source": [
    "def on_mouse(event, x, y, flags, _):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        oldx, oldy = -1, -1\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), (255, 255, 255), 20, cv2.LINE_AA)\n",
    "            oldx, oldy = x, y\n",
    "            cv2.imshow('img', img)\n",
    "\n",
    "            \n",
    "def norm_digit(img):\n",
    "    # 무게 중심 좌표 추출\n",
    "    m = cv2.moments(img)\n",
    "    cx = m['m10'] / m['m00']\n",
    "    cy = m['m01'] / m['m00']\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # affine 행렬 생성\n",
    "    aff = np.array([[1, 0, w/2 - (cx + 0.5)], [0, 1, h/2 - (cy + 0.5)]], \n",
    "                   dtype=np.float32)\n",
    "    \n",
    "    # warpAffine을 이용해 기하학 변환\n",
    "    dst = cv2.warpAffine(img, aff, (0, 0))\n",
    "    return dst\n",
    "\n",
    "net = cv2.dnn.readNet('./self_trained_mnist/model.onnx')\n",
    "# net = cv2.dnn.readNet('./self_trained_mnist/model_no_opset.onnx')\n",
    "\n",
    "\n",
    "if net.empty():\n",
    "    print('Network load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "img = np.zeros((400, 400), np.uint8)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.setMouseCallback('img', on_mouse)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey()\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "    elif key == ord(' '):\n",
    "        blob = cv2.dnn.blobFromImage(norm_digit(img), 1/255., (28, 28))\n",
    "        net.setInput(blob)\n",
    "        prob = net.forward()\n",
    "\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(prob)\n",
    "        digit = maxLoc[0]\n",
    "\n",
    "        print(f'{digit} ({maxVal * 100:4.2f}%)')\n",
    "\n",
    "        img.fill(0)\n",
    "        cv2.imshow('img', img)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f665469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
