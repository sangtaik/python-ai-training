{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch10_seq2seq_tutorial_나의작업.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN1CkpHMao9hZtFV7GaRVgq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["출처 : https://wikidocs.net/86900"],"metadata":{"id":"unxtFu-21hwN"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"I8-4MYyT1Vqc","executionInfo":{"status":"ok","timestamp":1653609980782,"user_tz":-540,"elapsed":2979,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"outputs":[],"source":["import os\n","import re\n","import shutil\n","import zipfile\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import unicodedata\n","import urllib3\n","from tensorflow.keras.layers import Embedding, GRU, Dense\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","source":["http = urllib3.PoolManager()\n","url = 'http://www.manythings.org/anki/fra-eng.zip'\n","filename = 'fra-eng.zip'\n","path = os.getcwd()\n","zipfilename = os.path.join(path, filename)\n","with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n","    shutil.copyfileobj(r, out_file)\n","\n","with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n","    zip_ref.extractall(path)"],"metadata":{"id":"QwYOVfYw1bE7","executionInfo":{"status":"ok","timestamp":1653609982581,"user_tz":-540,"elapsed":763,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 이번 실습에서는 약 19만개의 데이터 중 33,000개의 샘플만을 사용할 예정입니다.\n","\n","num_samples = 33000"],"metadata":{"id":"XVr8sTDx1dxi","executionInfo":{"status":"ok","timestamp":1653610025099,"user_tz":-540,"elapsed":325,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 전처리 함수들을 구현합니다. 구두점 등을 제거하거나 단어와 구분해주기 위한 전처리입니다.\n","\n","def to_ascii(s):\n","  # 프랑스어 악센트(accent) 삭제\n","  # 예시 : 'déjà diné' -> deja dine\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                   if unicodedata.category(c) != 'Mn')\n","\n","def preprocess_sentence(sent):\n","  # 악센트 제거 함수 호출\n","  sent = to_ascii(sent.lower())\n","\n","  # 단어와 구두점 사이에 공백 추가.\n","  # ex) \"I am a student.\" => \"I am a student .\"\n","  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n","\n","  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환.\n","  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n","\n","  # 다수 개의 공백을 하나의 공백으로 치환\n","  sent = re.sub(r\"\\s+\", \" \", sent)\n","  return sent"],"metadata":{"id":"Ic30FJHh1oys","executionInfo":{"status":"ok","timestamp":1653610030730,"user_tz":-540,"elapsed":315,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 구현한 전처리 함수들을 임의의 문장을 입력으로 테스트해봅시다.\n","\n","# 전처리 테스트\n","en_sent = u\"Have you had dinner?\"\n","fr_sent = u\"Avez-vous déjà diné?\"\n","\n","print('전처리 전 영어 문장 :', en_sent)\n","print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n","print('전처리 전 프랑스어 문장 :', fr_sent)\n","print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaqPPFm11qKy","executionInfo":{"status":"ok","timestamp":1653610046478,"user_tz":-540,"elapsed":305,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"b49d0722-18c3-4eb0-bed3-640eb47f43c1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["전처리 전 영어 문장 : Have you had dinner?\n","전처리 후 영어 문장 : have you had dinner ?\n","전처리 전 프랑스어 문장 : Avez-vous déjà diné?\n","전처리 후 프랑스어 문장 : avez vous deja dine ?\n"]}]},{"cell_type":"code","source":["# 전체 데이터에서 33,000개의 샘플에 대해서 전처리를 수행합니다. \n","# 또한 훈련 과정에서 교사 강요(Teacher Forcing)을 사용할 예정이므로, \n","# 훈련 시 사용할 디코더의 입력 시퀀스와 실제값. 즉, 레이블에 해당되는 출력 시퀀스를 따로 분리하여 저장합니다. \n","# 입력 시퀀스에는 시작을 의미하는 토큰인 <sos>를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 <eos>를 추가합니다.\n","\n","def load_preprocessed_data():\n","  encoder_input, decoder_input, decoder_target = [], [], []\n","\n","  with open(\"fra.txt\", \"r\") as lines:\n","    for i, line in enumerate(lines):\n","      # source 데이터와 target 데이터 분리\n","      src_line, tar_line, _ = line.strip().split('\\t')\n","\n","      # source 데이터 전처리\n","      src_line = [w for w in preprocess_sentence(src_line).split()]\n","\n","      # target 데이터 전처리\n","      tar_line = preprocess_sentence(tar_line)\n","      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n","      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n","\n","      encoder_input.append(src_line)\n","      decoder_input.append(tar_line_in)\n","      decoder_target.append(tar_line_out)\n","\n","      if i == num_samples - 1:\n","        break\n","\n","  return encoder_input, decoder_input, decoder_target"],"metadata":{"id":"GqKuezgJ1t4i","executionInfo":{"status":"ok","timestamp":1653610102737,"user_tz":-540,"elapsed":354,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 이렇게 얻은 3개의 데이터셋 인코더의 입력, 디코더의 입력, 디코더의 레이블을 상위 5개 샘플만 출력해봅시다.\n","# sents_fra_in : 교사 강요에 필요한 입력\n","sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n","print('인코더의 입력 :',sents_en_in[:5])\n","print('디코더의 입력 :',sents_fra_in[:5])\n","print('디코더의 레이블 :',sents_fra_out[:5])\n","# 인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n","# 디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n","# 디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-rp3xpx17vm","executionInfo":{"status":"ok","timestamp":1653610192971,"user_tz":-540,"elapsed":1553,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"aece4baa-bae4-4a03-f3f2-14102bb9d905"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.']]\n","디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.']]\n","디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>']]\n"]}]},{"cell_type":"code","source":["# 케라스 토크나이저를 통해 단어 집합을 생성, 정수 인코딩을 진행 후 이어서 패딩을 진행합니다.\n","\n","tokenizer_en = Tokenizer(filters=\"\", lower=False)\n","tokenizer_en.fit_on_texts(sents_en_in)\n","encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n","encoder_input = pad_sequences(encoder_input, padding=\"post\")\n","\n","tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n","tokenizer_fra.fit_on_texts(sents_fra_in)\n","tokenizer_fra.fit_on_texts(sents_fra_out)\n","\n","decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n","decoder_input = pad_sequences(decoder_input, padding=\"post\")\n","\n","decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n","decoder_target = pad_sequences(decoder_target, padding=\"post\")"],"metadata":{"id":"WXlYdw3o2Bmj","executionInfo":{"status":"ok","timestamp":1653610195370,"user_tz":-540,"elapsed":1353,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 데이터의 크기(shape)를 확인합니다.\n","print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n","print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n","print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGv_EYmk2SKr","executionInfo":{"status":"ok","timestamp":1653610231511,"user_tz":-540,"elapsed":3,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"9076deac-c689-48d4-9d6e-27e3f03ae23f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["인코더의 입력의 크기(shape) : (33000, 8)\n","디코더의 입력의 크기(shape) : (33000, 16)\n","디코더의 레이블의 크기(shape) : (33000, 16)\n"]}]},{"cell_type":"code","source":["# 샘플은 총 33,000개 존재하며 영어 문장의 길이는 8, 프랑스어 문장의 길이는 16입니다. 단어 집합의 크기를 정의합니다.\n","\n","src_vocab_size = len(tokenizer_en.word_index) + 1\n","tar_vocab_size = len(tokenizer_fra.word_index) + 1\n","print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_y-DBFhF2WCj","executionInfo":{"status":"ok","timestamp":1653610238578,"user_tz":-540,"elapsed":270,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"0a9e2ba0-3107-473e-e158-acae01b3b727"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["영어 단어 집합의 크기 : 4672, 프랑스어 단어 집합의 크기 : 8153\n"]}]},{"cell_type":"code","source":["# 단어 집합의 크기는 각각 4,647개와 8,022개입니다. \n","# 단어로부터 정수를 얻는 딕셔너리와 정수로부터 단어를 얻는 딕셔너리를 각각 만들어줍니다. \n","# 이들은 훈련을 마치고 예측값과 실제값을 비교하는 단계에서 사용됩니다.\n","\n","src_to_index = tokenizer_en.word_index\n","index_to_src = tokenizer_en.index_word\n","tar_to_index = tokenizer_fra.word_index\n","index_to_tar = tokenizer_fra.index_word\n","# 테스트 데이터를 분리하기 전 데이터를 섞어줍니다. 이를 위해서 순서가 섞인 정수 시퀀스 리스트를 만듭니다.\n","\n","indices = np.arange(encoder_input.shape[0])\n","np.random.shuffle(indices)\n","print('랜덤 시퀀스 :',indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSqcio5h2boC","executionInfo":{"status":"ok","timestamp":1653610284574,"user_tz":-540,"elapsed":266,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"aa0b234d-34c6-4a42-9067-36e133af5c61"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["랜덤 시퀀스 : [15161 13846  8265 ... 32424  3967  7990]\n"]}]},{"cell_type":"code","source":["# 이를 데이터셋의 순서로 지정해주면 샘플들이 기존 순서와 다른 순서로 섞이게 됩니다.\n","\n","encoder_input = encoder_input[indices]\n","decoder_input = decoder_input[indices]\n","decoder_target = decoder_target[indices]\n","# 임의로 30,997번째 샘플을 출력해봅시다. \n","# 이때 decoder_input과 decoder_target은 데이터의 구조상으로 앞에 붙은 <sos> 토큰과 \n","# 뒤에 붙은 <eos>을 제외하면 동일한 정수 시퀀스를 가져야 합니다.\n","\n","print(encoder_input[30997])\n","# array([  5,   7, 638,   1,   0,   0,   0,   0], dtype=int32)\n","print(decoder_input[30997])\n","# array([  2,  18,   5,  16, 173,   1,   0,   0,   0,   0,   0,   0,   0,\n","#          0,   0,   0], dtype=int32)\n","print(decoder_target[30997])\n","# array([ 18,   5,  16, 173,   1,   3,   0,   0,   0,   0,   0,   0,   0,\n","#          0,   0,   0], dtype=int32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gN-AQ0sX2oJ0","executionInfo":{"status":"ok","timestamp":1653610386921,"user_tz":-540,"elapsed":268,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"e2d16d12-2116-47c8-ed66-9490e191e6b2"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[  5   7 109   8 695   1   0   0]\n","[  2   7   5  16 696  17 261   1   0   0   0   0   0   0   0   0]\n","[  7   5  16 696  17 261   1   3   0   0   0   0   0   0   0   0]\n"]}]},{"cell_type":"code","source":["# 저자의 경우 18, 5, 16, 173, 1이라는 동일 시퀀스를 확인했습니다. 이제 훈련 데이터의 10%를 테스트 데이터로 분리하겠습니다.\n","\n","n_of_val = int(33000*0.1)\n","print('검증 데이터의 개수 :',n_of_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBR-6pZG23-C","executionInfo":{"status":"ok","timestamp":1653610402050,"user_tz":-540,"elapsed":269,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"522bdcc2-041b-4126-97f1-d989e3bc15d8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["검증 데이터의 개수 : 3300\n"]}]},{"cell_type":"code","source":["# 33,000개의 10%에 해당되는 3,300개의 데이터를 테스트 데이터로 사용합니다.\n","\n","encoder_input_train = encoder_input[:-n_of_val]\n","decoder_input_train = decoder_input[:-n_of_val]\n","decoder_target_train = decoder_target[:-n_of_val]\n","\n","encoder_input_test = encoder_input[-n_of_val:]\n","decoder_input_test = decoder_input[-n_of_val:]\n","decoder_target_test = decoder_target[-n_of_val:]"],"metadata":{"id":"uxJI96EP3E1z","executionInfo":{"status":"ok","timestamp":1653610418197,"user_tz":-540,"elapsed":255,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# 훈련 데이터와 테스트 데이터의 크기(shape)를 출력해봅시다.\n","\n","print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n","print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n","print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n","print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n","print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n","print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NyfSnfod3IyC","executionInfo":{"status":"ok","timestamp":1653611072763,"user_tz":-540,"elapsed":309,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"ad9481d7-de3b-4224-851c-f1ce6791e8f6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 source 데이터의 크기 : (29700, 8)\n","훈련 target 데이터의 크기 : (29700, 16)\n","훈련 target 레이블의 크기 : (29700, 16)\n","테스트 source 데이터의 크기 : (3300, 8)\n","테스트 target 데이터의 크기 : (3300, 16)\n","테스트 target 레이블의 크기 : (3300, 16)\n"]}]},{"cell_type":"markdown","source":["2. 기계 번역기 만들기"],"metadata":{"id":"m-vXuDfg5sCO"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n","from tensorflow.keras.models import Model"],"metadata":{"id":"fSRfdvGl5tD0","executionInfo":{"status":"ok","timestamp":1653611102978,"user_tz":-540,"elapsed":280,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 임베딩 벡터의 차원과 LSTM의 은닉 상태의 크기를 64로 사용합니다.\n","# 왜 64 size일까?\n","embedding_dim = 64\n","hidden_units = 64"],"metadata":{"id":"P2P6Sc_z5v5C","executionInfo":{"status":"ok","timestamp":1653611128004,"user_tz":-540,"elapsed":305,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["인코더를 설계합니다. 인코더를 주목해보면 함수형 API(functional API)를 사용한다는 것 외에는 앞서 다른 실습에서 본 LSTM 설계와 크게 다르지는 않습니다. Masking은 패딩 토큰인 숫자 0의 경우에는 연산을 제외하는 역할을 수행합니다. 인코더의 내부 상태를 디코더로 넘겨주어야 하기 때문에 return_state=True로 설정합니다. 인코더에 입력을 넣으면 내부 상태를 리턴합니다.\n","\n","LSTM에서 state_h, state_c를 리턴받는데, 이는 각각 RNN 챕터에서 LSTM을 처음 설명할 때 언급하였던 은닉 상태와 셀 상태에 해당됩니다. 이 두 가지 상태를 encoder_states에 저장합니다. encoder_states를 디코더에 전달하므로서 이 두 가지 상태 모두를 디코더로 전달할 예정입니다. \n","이것이 앞서 배운 컨텍스트 벡터입니다."],"metadata":{"id":"cEU867MM55bN"}},{"cell_type":"code","source":["# 인코더\n","encoder_inputs = Input(shape=(None,))\n","enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n","enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n","encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n","encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n","encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"],"metadata":{"id":"RzcIzD5752D6","executionInfo":{"status":"ok","timestamp":1653611169123,"user_tz":-540,"elapsed":1561,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["디코더는 인코더의 마지막 은닉 상태로부터 초기 은닉 상태를 얻습니다. initial_state의 인자값으로 encoder_states를 주는 코드가 이에 해당됩니다. 디코더도 은닉 상태, 셀 상태를 리턴하기는 하지만 훈련 과정에서는 사용하지 않습니다. seq2seq의 디코더는 기본적으로 각 시점마다 다중 클래스 분류 문제를 풀고있습니다. 매 시점마다 프랑스어 단어 집합의 크기(tar_vocab_size)의 선택지에서 단어를 1개 선택하여 이를 이번 시점에서 예측한 단어로 택합니다. 다중 클래스 분류 문제이므로 출력층으로 소프트맥스 함수와 손실 함수를 크로스 엔트로피 함수를 사용합니다.\n","\n","categorical_crossentropy를 사용하려면 레이블은 원-핫 인코딩이 된 상태여야 합니다. 그런데 현재 decoder_outputs의 경우에는 원-핫 인코딩을 하지 않은 상태입니다. 원-핫 인코딩을 하지 않은 상태로 정수 레이블에 대해서 다중 클래스 분류 문제를 풀고자 하는 경우에는 categorical_crossentropy가 아니라 sparse_categorical_crossentropy를 사용하면 됩니다."],"metadata":{"id":"-Ie9qIot6FAb"}},{"cell_type":"code","source":["# 디코더\n","decoder_inputs = Input(shape=(None,))\n","dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n","dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n","dec_masking = Masking(mask_value=0.0)(dec_emb)\n","\n","# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n","decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n","\n","# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n","decoder_outputs, _, _ = decoder_lstm(dec_masking,\n","                                     initial_state=encoder_states)\n","\n","# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n","decoder_dense = Dense(tar_vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# 모델의 입력과 출력을 정의.\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"],"metadata":{"id":"eyk0r45J5795","executionInfo":{"status":"ok","timestamp":1653611205979,"user_tz":-540,"elapsed":1006,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# 모델을 훈련합니다. 128개의 배치 크기로 총 50 에포크 학습합니다. \n","# 테스트 데이터를 검증 데이터로 사용하여 훈련이 제대로 되고있는지 모니터링하겠습니다.\n","results = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n","          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n","          batch_size=128, epochs=50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY4IJFWw6F0q","executionInfo":{"status":"ok","timestamp":1653616941342,"user_tz":-540,"elapsed":142235,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"5861d52b-5e26-4190-faf6-9c7af46f4876"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["233/233 [==============================] - 104s 448ms/step - loss: 0.3378 - acc: 0.9183 - val_loss: 0.7785 - val_acc: 0.8659\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# Fit the model\n","# list all data in history\n","print(results.history.keys())\n","# summarize history for accuracy\n","plt.plot(results.history['acc'])\n","plt.plot(results.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(results.history['loss'])\n","plt.plot(results.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"vZAyrYD87GwK","executionInfo":{"status":"ok","timestamp":1653616959085,"user_tz":-540,"elapsed":788,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"31adf01e-c22e-4e46-ba50-1ae32d06b142"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["3. seq2seq 기계 번역기 동작시키기"],"metadata":{"id":"FEMIykjx7Kb8"}},{"cell_type":"markdown","source":["seq2seq는 훈련 과정(교사 강요)과 테스트 과정에서의 동작 방식이 다릅니다. 그래서 테스트 과정을 위해 모델을 다시 설계해주어야 합니다. 특히 디코더를 수정해야 합니다. 이번에는 번역 단계를 위해 모델을 수정하고 동작시켜보겠습니다.\n","\n","전체적인 번역 단계를 정리하면 아래와 같습니다.\n","\n","번역하고자 하는 입력 문장이 인코더로 입력되어 인코더의 마지막 시점의 은닉 상태와 셀 상태를 얻습니다.\n","인코더의 은닉 상태와 셀 상태, 그리고 토큰 <sos>를 디코더로 보냅니다.\n","디코더가 토큰 <eos>가 나올 때까지 다음 단어를 예측하는 행동을 반복합니다.\n","인코더의 입, 출력으로 사용하는 encoder_inputs와 encoder_states는 훈련 과정에서 이미 정의한 것들을 재사용합니다. 이렇게 되면 훈련 단계에 encoder_inputs와 encoder_states 사이에 있는 모든 층까지 전부 불러오게 되므로 결과적으로 훈련 단계에서 사용한 인코더를 그대로 재사용하게 됩니다. 이어서 디코더를 설계합니다. 테스트 단계에서는 디코더를 매 시점 별로 컨트롤 할 예정으로, 이를 위해서 이전 시점의 상태를 저장할 텐서인 decoder_state_input_h, decoder_state_input_c를 정의합니다. 매 시점 별로 디코더를 컨트롤하는 함수는 뒤에서 정의할 decode_sequence()로 해당 함수를 자세히 살펴봐야 합니다."],"metadata":{"id":"l1aNpwZZ89Ls"}},{"cell_type":"code","source":["# 인코더\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","# 디코더 설계 시작\n","# 이전 시점의 상태를 보관할 텐서\n","decoder_state_input_h = Input(shape=(hidden_units,))\n","decoder_state_input_c = Input(shape=(hidden_units,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# 훈련 때 사용했던 임베딩 층을 재사용\n","dec_emb2 = dec_emb_layer(decoder_inputs)\n","\n","# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n","decoder_states2 = [state_h2, state_c2]\n","\n","# 모든 시점에 대해서 단어 예측\n","decoder_outputs2 = decoder_dense(decoder_outputs2)\n","\n","# 수정된 디코더\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs2] + decoder_states2)"],"metadata":{"id":"Uj8O9pCN7LNS","executionInfo":{"status":"ok","timestamp":1653617004919,"user_tz":-540,"elapsed":695,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["테스트 단계에서의 동작을 위한 decode_sequence 함수를 구현합니다. \n","입력 문장이 들어오면 인코더는 마지막 시점까지 전개하여 마지막 시점의 은닉 상태와 셀 상태를 리턴합니다. \n","이 두 개의 값을 states_value에 저장합니다. 그리고 디코더의 초기 입력으로 <SOS>를 준비합니다. 이를 target_seq에 저장합니다. \n","이 두 가지 입력을 가지고 while문 안으로 진입하여 이 두 가지를 디코더의 입력으로 사용합니다. \n","이제 디코더는 현재 시점에 대해서 예측을 하게 되는데, 현재 시점의 예측 벡터가 output_tokens, 현재 시점의 은닉 상태가 h, 현재 시점의 셀 상태가 c입니다. \n","예측 벡터로부터 현재 시점의 예측 단어인 target_seq를 얻고, h와 c 이 두 개의 값은 states_value에 저장합니다. \n","그리고 while문의 다음 루프. 즉, 두번째 시점의 디코더의 입력으로 다시 target_seq와 states_value를 사용합니다. \n","이를 현재 시점의 예측 단어로 <eos>를 예측하거나 번역 문장의 길이가 50이 넘는 순간까지 반복합니다.\n"," 각 시점마다 번역된 어는 decoded_sentence에 누적하여 저장하였다가 최종 번역 시퀀스로 리턴합니다.\n"],"metadata":{"id":"bVwvr4la9RiE"}},{"cell_type":"code","source":["\n","\n","def decode_sequence(input_seq):\n","  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n","  states_value = encoder_model.predict(input_seq)\n","\n","  # <SOS>에 해당하는 정수 생성\n","  target_seq = np.zeros((1,1))\n","  target_seq[0, 0] = tar_to_index['<sos>']\n","\n","  stop_condition = False\n","  decoded_sentence = ''\n","\n","  # stop_condition이 True가 될 때까지 루프 반복\n","  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n","  while not stop_condition:\n","    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n","    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","    # 예측 결과를 단어로 변환\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_char = index_to_tar[sampled_token_index]\n","\n","    # 현재 시점의 예측 단어를 예측 문장에 추가\n","    decoded_sentence += ' '+sampled_char\n","\n","    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n","    if (sampled_char == '<eos>' or\n","        len(decoded_sentence) > 50):\n","        stop_condition = True\n","\n","    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n","    target_seq = np.zeros((1,1))\n","    target_seq[0, 0] = sampled_token_index\n","\n","    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n","    states_value = [h, c]\n","\n","  return decoded_sentence"],"metadata":{"id":"ZOf2Naqx9D0h","executionInfo":{"status":"ok","timestamp":1653617007971,"user_tz":-540,"elapsed":304,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# 결과 확인을 위한 함수를 만듭니다. \n","# seq_to_src 함수는 영어 문장에 해당하는 정수 시퀀스를 입력받으면 정수로부터 영어 단어를 리턴하는 index_to_src를 통해 영어 문장으로 변환합니다.\n","# seq_to_tar은 프랑스어에 해당하는 정수 시퀀스를 입력받으면 정수로부터 프랑스어 단어를 리턴하는 index_to_tar을 통해 프랑스어 문장으로 변환합니다.\n","\n","# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq_to_src(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0):\n","      sentence = sentence + index_to_src[encoded_word] + ' '\n","  return sentence\n","\n","# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq_to_tar(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n","      sentence = sentence + index_to_tar[encoded_word] + ' '\n","  return sentence"],"metadata":{"id":"14i5hL649ZAr","executionInfo":{"status":"ok","timestamp":1653617008954,"user_tz":-540,"elapsed":2,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# 훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력해봅시다.\n","\n","for seq_index in [3, 50, 100, 300, 1001]:\n","  input_seq = encoder_input_train[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","\n","  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n","  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n","  print(\"번역문장 :\",decoded_sentence[1:-5])\n","  print(\"-\"*50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cogRKAOhAAZD","executionInfo":{"status":"ok","timestamp":1653617014136,"user_tz":-540,"elapsed":3669,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"9b83182f-4336-4aba-b8f1-73619bdd969b"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["입력문장 : can i sing ? \n","정답문장 : puis je chanter ? \n","번역문장 : puis je demander a tom ? \n","--------------------------------------------------\n","입력문장 : i m poor at tennis . \n","정답문장 : je suis mediocre au tennis . \n","번역문장 : je suis mediocre au tennis . \n","--------------------------------------------------\n","입력문장 : you nearly died . \n","정답문장 : vous etes presque morte . \n","번역문장 : vous etes presque mort . \n","--------------------------------------------------\n","입력문장 : do you feel lucky ? \n","정답문장 : te sens tu chanceux ? \n","번역문장 : vous sentez vous en veine ? \n","--------------------------------------------------\n","입력문장 : we waited outside . \n","정답문장 : nous avons attendu dehors . \n","번역문장 : nous attendimes dehors . \n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["# 테스트 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력해봅시다.\n","\n","for seq_index in [3, 50, 100, 300, 1001]:\n","  input_seq = encoder_input_test[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","\n","  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n","  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n","  print(\"번역문장 :\",decoded_sentence[1:-5])\n","  print(\"-\"*50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHq-PTDWCzCm","executionInfo":{"status":"ok","timestamp":1653617026070,"user_tz":-540,"elapsed":2161,"user":{"displayName":"Sang-Taik Jung","userId":"01715234492257531936"}},"outputId":"cfa568f7-d0e8-470e-e601-94261438f212"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["입력문장 : you re conceited . \n","정답문장 : vous etes suffisants . \n","번역문장 : vous etes suffisante . \n","--------------------------------------------------\n","입력문장 : he is in trouble . \n","정답문장 : il a des ennuis . \n","번역문장 : il a la baraka . \n","--------------------------------------------------\n","입력문장 : tom tried to sleep . \n","정답문장 : tom essaya de dormir . \n","번역문장 : tom a parle de marie . \n","--------------------------------------------------\n","입력문장 : i dozed . \n","정답문장 : je me suis assoupi . \n","번역문장 : j ai vu . \n","--------------------------------------------------\n","입력문장 : i ve been tricked . \n","정답문장 : on m a trompe . \n","번역문장 : j ai ete expulse . \n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"sAn9gcANQVoQ"},"execution_count":null,"outputs":[]}]}